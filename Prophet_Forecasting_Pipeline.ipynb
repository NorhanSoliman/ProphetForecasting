{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e547f41",
   "metadata": {},
   "source": [
    "## Demand Forecasting Using Prophet on Quik Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "732d0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import math\n",
    "import itertools \n",
    "from scipy import stats\n",
    "import time\n",
    "import pickle\n",
    "from openpyxl import Workbook\n",
    "\n",
    "\n",
    "#for data cleaning\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "#matplotlib libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "\n",
    "#date libraries\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta, date\n",
    "import holidays\n",
    "\n",
    "#prophet library\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "#pandas options\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#matplotlib setting defaults\n",
    "sns.set(font=\"Arial\",\n",
    "        rc={\n",
    " \"axes.axisbelow\": False,\n",
    " \"axes.edgecolor\": \"lightgrey\",\n",
    " \"axes.facecolor\": \"None\",\n",
    " \"axes.grid\": False,\n",
    " \"axes.labelcolor\": \"dimgrey\",\n",
    " \"axes.spines.right\": False,\n",
    " \"axes.spines.top\": False,\n",
    " \"figure.facecolor\": \"white\",\n",
    " \"lines.solid_capstyle\": \"round\",\n",
    " \"patch.edgecolor\": \"w\",\n",
    " \"patch.force_edgecolor\": True,\n",
    " \"text.color\": \"dimgrey\",\n",
    " \"xtick.bottom\": False,\n",
    " \"xtick.color\": \"dimgrey\",\n",
    " \"xtick.direction\": \"out\",\n",
    " \"xtick.top\": False,\n",
    " \"ytick.color\": \"dimgrey\",\n",
    " \"ytick.direction\": \"out\",\n",
    " \"ytick.left\": False,\n",
    " \"ytick.right\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15808cd9",
   "metadata": {},
   "source": [
    "### Assumptions For Historical Data Processing:\n",
    "1. The unprocessed historical data stored in a folder og_data\n",
    "2. The files inside og_data are all .csv files\n",
    "3. Columns have the same names as given: 'order_id', 'merchant_id', 'order_received_timestamp'\n",
    "4. All csv files have format: anon_quik_'month'_'year'.csv\n",
    "### Notes:\n",
    "1. All intermediate processed files are stored in processed_data_10_mins\n",
    "2. The final processed files is generated in the main working directory as quik_data_all_final_10_mins.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c01c44",
   "metadata": {},
   "source": [
    "### Helper Functions For Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9b83c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_merchant_ids(input_csv, output_csv):\n",
    "    # Define the mapping of merchant IDs to merchant names\n",
    "    with open('merchant_id_map.json', 'r') as f:\n",
    "        merchant_id_map = json.load(f)\n",
    "    try:\n",
    "        # Open input and output files\n",
    "        with open(input_csv, 'r') as infile, open(output_csv, 'w', newline='') as outfile:\n",
    "            reader = csv.reader(infile)\n",
    "            writer = csv.writer(outfile)\n",
    "            # Iterate through each row in the input file\n",
    "            for row in reader:\n",
    "                # Check if the first column (merchant ID) exists in the mapping\n",
    "                if row[1] in merchant_id_map:\n",
    "                    # Replace the merchant ID with the corresponding merchant name\n",
    "                    row[1] = merchant_id_map[row[1]]\n",
    "                else:\n",
    "                    if row[1] == \"merchant_id\":\n",
    "                        # Skip the header row\n",
    "                        writer.writerow(row)\n",
    "                        continue\n",
    "                    # If the merchant ID is not found in the mapping, skip this row\n",
    "                    print(f\"Merchant ID {row[1]} not found in mapping.\")\n",
    "                    merchant_id_map[row[1]] = f\"merchant_{len(merchant_id_map) + 1}\"\n",
    "                    f = open('merchant_id_map.json', 'w')\n",
    "                    f.write(json.dumps(merchant_id_map))\n",
    "                    f.close()\n",
    "                    print(f\"Added new mapping: {row[1]} -> {merchant_id_map[row[1]]}\")\n",
    "                    row[1] = merchant_id_map[row[1]]\n",
    "                    print(f\"Replaced merchant ID with new mapping: {row[1]}\")\n",
    "\n",
    "\n",
    "                # Write the modified row to the output file\n",
    "                writer.writerow(row)\n",
    "\n",
    "        print(\"Mapping completed successfully.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Make sure 'quick_data.csv' exists in the current directory.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "def drop_columns(input_csv, output_csv, columns_to_keep):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Select only the specified columns to keep\n",
    "    df_filtered = df[columns_to_keep]\n",
    "    \n",
    "    # check if directory does not exists\n",
    "    if not os.path.exists(output_csv.split('/')[0]):\n",
    "        os.makedirs(output_csv.split('/')[0])\n",
    "    # Save the filtered DataFrame to a new CSV file\n",
    "    df_filtered.to_csv(output_csv, index=False)\n",
    "    print(f\"Filtered CSV saved as {output_csv}\")\n",
    "def merge_csv_files(input_files, output_file):\n",
    "    # Read all CSV files and combine them into a single DataFrame\n",
    "    df_list = [pd.read_csv(file) for file in input_files]\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined CSV saved as {output_file}\")\n",
    "def split_merchants():\n",
    "    # Load the CSV data into a DataFrame\n",
    "    data = pd.read_csv(\"quik_data_all.csv\")\n",
    "\n",
    "    # Get unique merchant IDs\n",
    "    unique_merchant_ids = data['merchant_id'].unique()\n",
    "\n",
    "    # Loop through unique merchant IDs and save data for each to a new CSV file\n",
    "    i = 0\n",
    "    for merchant_id in unique_merchant_ids:\n",
    "        # Filter the data for the current merchant_id\n",
    "        merchant_data = data[data['merchant_id'] == merchant_id]\n",
    "\n",
    "        # Define the output filename using the merchant_id\n",
    "        output_filename = f\"separate_merchants/{merchant_id}.csv\"\n",
    "\n",
    "        # Save to CSV (optional: index=False to avoid including the index column in the output)\n",
    "        merchant_data.to_csv(output_filename, index=False)\n",
    "        i = i + 1\n",
    "\n",
    "    print(\"Data has been split into separate files based on unique merchant_id values.\")\n",
    "def aggregate_orders_per_n_minutes(csv_file, output_csv, n_minutes):\n",
    "    freq = f'{n_minutes}T'\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Convert the order_received_timestamp to a datetime object\n",
    "    df['order_received_timestamp'] = pd.to_datetime(df['order_received_timestamp'])\n",
    "    \n",
    "    # Set the order_received_timestamp as the index\n",
    "    df.set_index('order_received_timestamp', inplace=True)\n",
    "    \n",
    "    # Group by merchant_id and resample the data in 20-minute periods to count orders\n",
    "    order_counts = df.groupby('merchant_id').resample(freq).size().reset_index(name='order_count')\n",
    "    \n",
    "    # Print the result\n",
    "    print(order_counts)\n",
    "    \n",
    "    # Save the result to a new CSV file\n",
    "    order_counts.to_csv(output_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f8d8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(time_window, data_dir):\n",
    "    processed_files_dir = f'processed_data_{time_window}_mins'\n",
    "    processed_files = []\n",
    "\n",
    "    # check if directory does not exists\n",
    "    if not os.path.exists(processed_files_dir):\n",
    "        os.makedirs(processed_files_dir)\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        # Specify the input and output CSV file paths and the columns to keep\n",
    "        input_csv = ''.join([data_dir, '/', filename])\n",
    "        output_csv = input_csv.split('/')[1].replace('anon_', '')\n",
    "        output_csv = ''.join([processed_files_dir, '/', output_csv])\n",
    "        # print(f'input file: {input_csv}')\n",
    "        # print(f'output file: {output_csv}')\n",
    "        columns_to_keep = ['order_id', 'merchant_id', 'order_received_timestamp']  # Replace with your column names\n",
    "\n",
    "        # Call the function to drop columns\n",
    "        drop_columns(input_csv, output_csv, columns_to_keep)\n",
    "\n",
    "\n",
    "        input_csv = output_csv\n",
    "        tmp = input_csv.split('.')[0]\n",
    "        output_csv = f'{tmp}_mapped.csv'\n",
    "        # print(f'input file: {input_csv}')\n",
    "        # print(f'output file: {output_csv}')\n",
    "\n",
    "        # map merchant IDs to merchant names\n",
    "        map_merchant_ids(input_csv, output_csv)\n",
    "\n",
    "        input_csv = output_csv\n",
    "        output_csv = output_csv.replace('_mapped', '_final')\n",
    "        print(f'input file: {input_csv}')\n",
    "        print(f'output file: {output_csv}')\n",
    "        # Call the function to count orders\n",
    "        aggregate_orders_per_n_minutes(input_csv, output_csv, time_window)\n",
    "        processed_files.append(output_csv)\n",
    "    dataset_file = f'quik_data_all_final_{time_window}_mins.csv'\n",
    "    merge_csv_files(processed_files, dataset_file)\n",
    "    # print(\"Inside the function: \")\n",
    "    # print(dataset_file)\n",
    "    return dataset_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cfae1b",
   "metadata": {},
   "source": [
    "### Loading All Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e93449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_name = process_data(10, \"og_data\") # process_data(time_window, data_dir) \n",
    "df = pd.read_csv(dataset_file_name) \n",
    "df.columns = df.columns.str.lower()\n",
    "df['order_received_timestamp'] = pd.to_datetime(df['order_received_timestamp'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d848272f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-12-01 00:00:00'), Timestamp('2024-02-29 23:50:00'))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df['order_received_timestamp']), max(df['order_received_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81a9871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>order_received_timestamp</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2023-12-01 00:10:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2023-12-01 00:20:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2023-12-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2023-12-01 00:40:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2023-12-01 00:50:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merchant_id order_received_timestamp  order_count\n",
       "0  merchant_1      2023-12-01 00:10:00            1\n",
       "1  merchant_1      2023-12-01 00:20:00            2\n",
       "2  merchant_1      2023-12-01 00:30:00            0\n",
       "3  merchant_1      2023-12-01 00:40:00            1\n",
       "4  merchant_1      2023-12-01 00:50:00            2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d9d553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.groupby(['order_received_timestamp', 'merchant_id']).agg({'order_count': 'sum'}).reset_index().sort_values(['merchant_id', 'order_received_timestamp']) #groups the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "754fd52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_received_timestamp</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-01 00:10:00</td>\n",
       "      <td>merchant_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-12-01 00:20:00</td>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-12-01 00:30:00</td>\n",
       "      <td>merchant_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-12-01 00:40:00</td>\n",
       "      <td>merchant_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-12-01 00:50:00</td>\n",
       "      <td>merchant_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_received_timestamp merchant_id  order_count\n",
       "6       2023-12-01 00:10:00  merchant_1            1\n",
       "13      2023-12-01 00:20:00  merchant_1            2\n",
       "21      2023-12-01 00:30:00  merchant_1            0\n",
       "29      2023-12-01 00:40:00  merchant_1            1\n",
       "37      2023-12-01 00:50:00  merchant_1            2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95355882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_received_timestamp</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141349</th>\n",
       "      <td>2024-02-29 23:10:00</td>\n",
       "      <td>merchant_9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141358</th>\n",
       "      <td>2024-02-29 23:20:00</td>\n",
       "      <td>merchant_9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141366</th>\n",
       "      <td>2024-02-29 23:30:00</td>\n",
       "      <td>merchant_9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141374</th>\n",
       "      <td>2024-02-29 23:40:00</td>\n",
       "      <td>merchant_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141380</th>\n",
       "      <td>2024-02-29 23:50:00</td>\n",
       "      <td>merchant_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_received_timestamp merchant_id  order_count\n",
       "141349      2024-02-29 23:10:00  merchant_9            2\n",
       "141358      2024-02-29 23:20:00  merchant_9            0\n",
       "141366      2024-02-29 23:30:00  merchant_9            0\n",
       "141374      2024-02-29 23:40:00  merchant_9            1\n",
       "141380      2024-02-29 23:50:00  merchant_9            1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a815ed11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_1</th>\n",
       "      <th>merchant_10</th>\n",
       "      <th>merchant_11</th>\n",
       "      <th>merchant_12</th>\n",
       "      <th>merchant_2</th>\n",
       "      <th>merchant_3</th>\n",
       "      <th>merchant_4</th>\n",
       "      <th>merchant_5</th>\n",
       "      <th>merchant_6</th>\n",
       "      <th>merchant_7</th>\n",
       "      <th>merchant_8</th>\n",
       "      <th>merchant_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_received_timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-29 23:10:00</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29 23:20:00</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29 23:30:00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29 23:40:00</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29 23:50:00</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "merchant_id               merchant_1  merchant_10  merchant_11  merchant_12  \\\n",
       "order_received_timestamp                                                      \n",
       "2024-02-29 23:10:00             1.00         1.00         1.00         1.00   \n",
       "2024-02-29 23:20:00             1.00         1.00         0.00          NaN   \n",
       "2024-02-29 23:30:00             0.00         1.00         0.00          NaN   \n",
       "2024-02-29 23:40:00             1.00         2.00         0.00          NaN   \n",
       "2024-02-29 23:50:00             1.00         1.00         1.00          NaN   \n",
       "\n",
       "merchant_id               merchant_2  merchant_3  merchant_4  merchant_5  \\\n",
       "order_received_timestamp                                                   \n",
       "2024-02-29 23:10:00             1.00        2.00        1.00        0.00   \n",
       "2024-02-29 23:20:00             1.00        1.00        2.00        0.00   \n",
       "2024-02-29 23:30:00             3.00        0.00         NaN        0.00   \n",
       "2024-02-29 23:40:00             1.00        1.00         NaN        0.00   \n",
       "2024-02-29 23:50:00              NaN         NaN         NaN        1.00   \n",
       "\n",
       "merchant_id               merchant_6  merchant_7  merchant_8  merchant_9  \n",
       "order_received_timestamp                                                  \n",
       "2024-02-29 23:10:00              NaN         NaN        1.00        2.00  \n",
       "2024-02-29 23:20:00              NaN         NaN        0.00        0.00  \n",
       "2024-02-29 23:30:00              NaN         NaN        3.00        0.00  \n",
       "2024-02-29 23:40:00              NaN         NaN        0.00        1.00  \n",
       "2024-02-29 23:50:00              NaN         NaN        1.00        1.00  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_orders_df = agg_df.pivot(index='order_received_timestamp', columns='merchant_id', values='order_count')\n",
    "total_orders_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687b7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "for column in total_orders_df.columns:\n",
    "    plt.figure(figsize=(10, 4))  \n",
    "    plt.plot(total_orders_df.index, total_orders_df[column], marker='o', linestyle='-')  \n",
    "    plt.title(f\"Order Trend for {column}\")\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Number of Orders')\n",
    "    plt.grid(True)  \n",
    "    plt.xticks(rotation=45)  \n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42cde772",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = total_orders_df.index.min()\n",
    "total_orders_df = total_orders_df[total_orders_df.index >= start_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57743459",
   "metadata": {},
   "source": [
    "### Identifying and Removing Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34f25d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(input_data):\n",
    "    '''\n",
    "    This function returns dataframe with information about the percentage of nulls in each column and the column data type.\n",
    "    \n",
    "    input: pandas df\n",
    "    output: pandas df\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    total = input_data.isnull().sum()\n",
    "    percent = (input_data.isnull().sum()/input_data.isnull().count()*100)\n",
    "    table = pd.concat([total, percent], axis = 1, keys = ['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in input_data.columns: \n",
    "        dtype = str(input_data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    table[\"Types\"] = types\n",
    "    return(pd.DataFrame(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73a81590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merchant_1</th>\n",
       "      <td>52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_10</th>\n",
       "      <td>46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_11</th>\n",
       "      <td>6573</td>\n",
       "      <td>50.16</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_12</th>\n",
       "      <td>9147</td>\n",
       "      <td>69.80</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_7</th>\n",
       "      <td>14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percent    Types\n",
       "merchant_id                         \n",
       "merchant_1      52     0.40  float64\n",
       "merchant_10     46     0.35  float64\n",
       "merchant_11   6573    50.16  float64\n",
       "merchant_12   9147    69.80  float64\n",
       "merchant_2       2     0.02  float64\n",
       "merchant_3       1     0.01  float64\n",
       "merchant_4       9     0.07  float64\n",
       "merchant_5       2     0.02  float64\n",
       "merchant_6      10     0.08  float64\n",
       "merchant_7      14     0.11  float64\n",
       "merchant_8       2     0.02  float64\n",
       "merchant_9       9     0.07  float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data(total_orders_df) #checks for null values for each merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b29cab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merchant_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percent    Types\n",
       "merchant_id                         \n",
       "merchant_1       0     0.00  float64\n",
       "merchant_10      0     0.00  float64\n",
       "merchant_11      0     0.00  float64\n",
       "merchant_12      0     0.00  float64\n",
       "merchant_2       0     0.00  float64\n",
       "merchant_3       0     0.00  float64\n",
       "merchant_4       0     0.00  float64\n",
       "merchant_5       0     0.00  float64\n",
       "merchant_6       0     0.00  float64\n",
       "merchant_7       0     0.00  float64\n",
       "merchant_8       0     0.00  float64\n",
       "merchant_9       0     0.00  float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_orders_df.fillna(0, inplace=True) #filling nan values with zeros\n",
    "#assuming there was no orders at that 20 minute period for that merchant\n",
    "\n",
    "missing_data(total_orders_df) #check missing values again to make sure there's none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffe7eb",
   "metadata": {},
   "source": [
    "#### This section groups merchants by the volume of data. The higher volume data the better for forecasting since we can forecast past the noise and end up with lower error bars. This helped understand why some merchats had higher error bars than other merchants (['merchant_12', 'merchant_11', 'merchant_7', 'merchant_6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d267f93",
   "metadata": {},
   "source": [
    "### Category Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34c715c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_daily_orders = total_orders_df.apply(np.mean, axis=0).sort_values() #typical order volume per merchant across all timestamps.\n",
    "\n",
    "low, mid = np.percentile(avg_daily_orders, [33, 66]) #thresholds for low, mid, and high order volumes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "021cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of merchants based on order volume categories\n",
    "low_vol_columns = list(avg_daily_orders[avg_daily_orders <= low].index)\n",
    "mid_vol_columns = list(avg_daily_orders[(avg_daily_orders > low) & (avg_daily_orders < mid)].index)\n",
    "high_vol_columns = list(avg_daily_orders[avg_daily_orders >= mid].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c92e7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merchant_10', 'merchant_1', 'merchant_4', 'merchant_5']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_vol_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f189d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merchant_12', 'merchant_11', 'merchant_7', 'merchant_6']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_vol_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ff9df",
   "metadata": {},
   "source": [
    "### Visualizing low, mid, high columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441c736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(12, 6))  \n",
    "# for merchant in low_vol_columns:\n",
    "#     plt.plot(total_orders_df.index, total_orders_df[merchant], label=merchant)\n",
    "\n",
    "# plt.title('Order Trends for Low Volume Merchants')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Number of Orders')\n",
    "# plt.legend(title='Merchant', loc='best')  \n",
    "# plt.grid(True)  \n",
    "# plt.xticks(rotation=45)  \n",
    "# plt.tight_layout() \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c56820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6)) \n",
    "# for merchant in mid_vol_columns:\n",
    "#     plt.plot(total_orders_df.index, total_orders_df[merchant], label=merchant)\n",
    "\n",
    "# plt.title('Order Trends for Mid Volume Merchants')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Number of Orders')\n",
    "# plt.legend(title='Merchant', loc='best', bbox_to_anchor=(1.1, 1.05))  # Positioning the legend outside the plot area\n",
    "# plt.grid(True)  # Adding a grid for better readability\n",
    "# plt.xticks(rotation=30)  \n",
    "# plt.tight_layout() \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b6e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))  # Set a suitable figure size\n",
    "# for merchant in high_vol_columns:\n",
    "#     plt.plot(total_orders_df.index, total_orders_df[merchant], label=merchant)\n",
    "\n",
    "# plt.title('Order Trends for High Volume Merchants')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Number of Orders')\n",
    "# plt.legend(title='Merchant', loc='best', bbox_to_anchor=(1.1, 1.05))  # Properly title the legend and adjust its position\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.grid(True)  # Optionally add a grid\n",
    "# plt.tight_layout()  # Adjust layout\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a513876",
   "metadata": {},
   "source": [
    "### Model Latest Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2787f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "def load_most_recent_checkpoint(directory: str) -> object:\n",
    "    \"\"\"\n",
    "    Load the most recent Prophet model checkpoint from the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path to the directory containing the checkpoint files.\n",
    "\n",
    "    Returns:\n",
    "    - object: The loaded Prophet model from the most recent checkpoint.\n",
    "    \"\"\"\n",
    "    directory_path = Path(directory)\n",
    "\n",
    "     # Create the directory if it doesn't exist\n",
    "    if not directory_path.exists():\n",
    "        directory_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Directory created: {directory}\")\n",
    "        return None  # Return None as there's no checkpoint to load\n",
    "\n",
    "    # List all .pkl files in the directory\n",
    "    pkl_files = list(directory_path.glob(\"prophet_model_*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"No .pkl files found in the directory.\")\n",
    "        return None\n",
    "\n",
    "    # Extract dates from filenames and sort by date (newest first)\n",
    "    def extract_date_from_filename(file):\n",
    "        date_str = file.stem.split('_')[-1]  # Extract the date part from the filename\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d')  # Convert to datetime object\n",
    "\n",
    "    # Sort files by extracted date\n",
    "    pkl_files.sort(key=lambda file: extract_date_from_filename(file), reverse=True)\n",
    "\n",
    "    # Get the most recent file\n",
    "    most_recent_file = pkl_files[0]\n",
    "\n",
    "    print(f\"Most recent model checkpoint: {most_recent_file}\")\n",
    "\n",
    "    # Load the most recent model checkpoint (assuming itâ€™s a pickle file)\n",
    "    with open(most_recent_file, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64873e3f",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING AND BACKTESTING PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3859e4",
   "metadata": {},
   "source": [
    "Ranges give on Prophet's documentation\n",
    "\n",
    "1. changepoint_prior_scale [0.001, 0.5] \n",
    "2. seasonality_prior_scale [0.01, 10]\n",
    "3. holidays_prior_scale [0.01, 10] \n",
    "4. seasonality_mode ['additive', 'multiplicative'].\n",
    "5. changepoint_range [0.5, 0.95]\n",
    "\n",
    "https://facebook.github.io/prophet/docs/diagnostics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0dde5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoint_prior_scale_range = np.linspace(0.001, 0.5, num=5).tolist()\n",
    "seasonality_prior_scale_range = np.linspace(0.01, 10, num=5).tolist()\n",
    "holidays_prior_scale_range = np.linspace(0.01, 10, num=5).tolist()\n",
    "seasonality_mode_options = ['additive', 'multiplicative']\n",
    "changepoint_range_range = list(np.linspace(0.5, 0.95, num=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning for the above five hyperparameters (takes more than 24 hours running)\n",
    "# Already done this step and stored the optimized values in a dictionary below\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# dicts = {}\n",
    "\n",
    "# for feature in total_orders_df.columns:\n",
    "  \n",
    "#     category_df = total_orders_df[feature].copy().reset_index()\n",
    "#     category_df.columns = [\"ds\", \"y\"]\n",
    "\n",
    "#     category_df[[\"y\"]] = category_df[[\"y\"]].apply(pd.to_numeric)\n",
    "#     category_df[\"ds\"] = pd.to_datetime(category_df[\"ds\"])\n",
    "    \n",
    "#     param_grid = {  \n",
    "#         \"changepoint_prior_scale\": changepoint_prior_scale_range,\n",
    "#         \"seasonality_prior_scale\": seasonality_prior_scale_range,\n",
    "#         'holidays_prior_scale': holidays_prior_scale_range,\n",
    "#         'seasonality_mode': seasonality_mode_options,\n",
    "#         'changepoint_range': changepoint_range_range}\n",
    "\n",
    "#     # Generate all combinations of parameters\n",
    "#     all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "#     rmses = []\n",
    "#     maes = []\n",
    "\n",
    "#     # Use cross validation to evaluate all parameters\n",
    "#     for params in all_params:\n",
    "#         m = Prophet(**params).fit(category_df)  # Fit model with given params\n",
    "#         df_cv = cross_validation(m, initial=\"60 days\", period=\"5 days\", horizon = \"1 days\") \n",
    "#         df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "#         print(df_p)\n",
    "#         rmses.append(df_p[\"rmse\"].values[0])\n",
    "#         maes.append(df_p[\"mae\"].values[0])\n",
    "\n",
    "#     # Find the best parameters\n",
    "#     tuning_results = pd.DataFrame(all_params)\n",
    "#     tuning_results[\"rmse\"] = rmses\n",
    "#     tuning_results[\"mae\"] = maes\n",
    "\n",
    "#     params_dict = dict(tuning_results.sort_values(\"rmse\").reset_index(drop=True).iloc[0])\n",
    "#     params_dict[\"column\"] = feature \n",
    "    \n",
    "#     dicts[feature] = params_dict\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80515d76",
   "metadata": {},
   "source": [
    "Here is a dictionary of the optimized parameters for each merchant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd4ee9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {'merchant_1': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 7.5024999999999995,\n",
    "  'holidays_prior_scale': 10.0,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.5,\n",
    "  'rmse': 3.4315968192683637,\n",
    "  'mae': 2.4984342328440046,\n",
    "  'column': 'merchant_1'},\n",
    " 'merchant_10': {'changepoint_prior_scale': 0.12575,\n",
    "  'seasonality_prior_scale': 5.005,\n",
    "  'holidays_prior_scale': 10.0,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.6125,\n",
    "  'rmse': 3.5954550911116465,\n",
    "  'mae': 2.5557456620858,\n",
    "  'column': 'merchant_10'},\n",
    " 'merchant_11': {'changepoint_prior_scale': 0.2505,\n",
    "  'seasonality_prior_scale': 7.5024999999999995,\n",
    "  'holidays_prior_scale': 7.5024999999999995,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.6125,\n",
    "  'rmse': 1.7238502662395094,\n",
    "  'mae': 1.299743933957384,\n",
    "  'column': 'merchant_11'},\n",
    " 'merchant_12': {'changepoint_prior_scale': 0.37525,\n",
    "  'seasonality_prior_scale': 0.01,\n",
    "  'holidays_prior_scale': 7.5024999999999995,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.95,\n",
    "  'rmse': 2.6299807073691883,\n",
    "  'mae': 2.0098218657752147,\n",
    "  'column': 'merchant_12'},\n",
    " 'merchant_2': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 5.005,\n",
    "  'holidays_prior_scale': 10.0,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.725,\n",
    "  'rmse': 3.0502628448731963,\n",
    "  'mae': 2.221268396746129,\n",
    "  'column': 'merchant_2'},\n",
    " 'merchant_3': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 5.005,\n",
    "  'holidays_prior_scale': 0.01,\n",
    "  'seasonality_mode': 'additive',\n",
    "  'changepoint_range': 0.5,\n",
    "  'rmse': 2.361647507971563,\n",
    "  'mae': 1.7546935832409052,\n",
    "  'column': 'merchant_3'},\n",
    " 'merchant_4': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 2.5075,\n",
    "  'holidays_prior_scale': 0.01,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.5,\n",
    "  'rmse': 3.709540232072044,\n",
    "  'mae': 2.6422456357755504,\n",
    "  'column': 'merchant_4'},\n",
    " 'merchant_5': {'changepoint_prior_scale': 0.5,\n",
    "  'seasonality_prior_scale': 2.5075,\n",
    "  'holidays_prior_scale': 0.01,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.95,\n",
    "  'rmse': 3.2533279397777206,\n",
    "  'mae': 2.3681656901119186,\n",
    "  'column': 'merchant_5'},\n",
    " 'merchant_6': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 2.5075,\n",
    "  'holidays_prior_scale': 2.5075,\n",
    "  'seasonality_mode': 'additive',\n",
    "  'changepoint_range': 0.8374999999999999,\n",
    "  'rmse': 2.0234077366020458,\n",
    "  'mae': 1.5088789734778578,\n",
    "  'column': 'merchant_6'},\n",
    " 'merchant_7': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 0.01,\n",
    "  'holidays_prior_scale': 0.01,\n",
    "  'seasonality_mode': 'additive',\n",
    "  'changepoint_range': 0.5,\n",
    "  'rmse': 2.0137982163020816,\n",
    "  'mae': 1.4871130296584607,\n",
    "  'column': 'merchant_7'},\n",
    " 'merchant_8': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 5.005,\n",
    "  'holidays_prior_scale': 7.5024999999999995,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.725,\n",
    "  'rmse': 3.0955259810842684,\n",
    "  'mae': 2.3027168995176646,\n",
    "  'column': 'merchant_8'},\n",
    " 'merchant_9': {'changepoint_prior_scale': 0.001,\n",
    "  'seasonality_prior_scale': 10.0,\n",
    "  'holidays_prior_scale': 5.005,\n",
    "  'seasonality_mode': 'multiplicative',\n",
    "  'changepoint_range': 0.5,\n",
    "  'rmse': 3.2519446602474082,\n",
    "  'mae': 2.336450967142641,\n",
    "  'column': 'merchant_9'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51152ed",
   "metadata": {},
   "source": [
    "### HOLIDAY DATA To Fetch UAE Hollidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "945e5f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ds       holiday  lower_window  upper_window\n",
      "0 2023-01-01  UAE-Holidays            -2             1\n",
      "1 2023-04-20  UAE-Holidays            -2             1\n",
      "2 2023-04-21  UAE-Holidays            -2             1\n",
      "3 2023-04-22  UAE-Holidays            -2             1\n",
      "4 2023-04-23  UAE-Holidays            -2             1\n",
      "5 2023-06-27  UAE-Holidays            -2             1\n",
      "6 2023-06-28  UAE-Holidays            -2             1\n",
      "7 2023-06-29  UAE-Holidays            -2             1\n",
      "8 2023-06-30  UAE-Holidays            -2             1\n",
      "9 2023-07-21  UAE-Holidays            -2             1\n",
      "           ds         holiday  lower_window  upper_window\n",
      "18 2024-06-15    UAE-Holidays            -2             1\n",
      "19 2024-06-16    UAE-Holidays            -2             1\n",
      "20 2024-06-17    UAE-Holidays            -2             1\n",
      "21 2024-06-18    UAE-Holidays            -2             1\n",
      "22 2024-07-07    UAE-Holidays            -2             1\n",
      "23 2024-09-15    UAE-Holidays            -2             1\n",
      "24 2024-12-02    UAE-Holidays            -2             1\n",
      "25 2024-12-03    UAE-Holidays            -2             1\n",
      "26 2023-12-30  Manual-Holiday            -2             1\n",
      "27 2023-12-31  Manual-Holiday            -2             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nourhan\\AppData\\Local\\Temp\\ipykernel_25360\\3431846932.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the holiday DataFrame\n",
    "holiday = pd.DataFrame([])\n",
    "\n",
    "# Fetch holidays for UAE for the years 2023 and 2024\n",
    "for date_, name in sorted(holidays.AE(years=[2023, 2024]).items()):\n",
    "    holiday = pd.concat([holiday, pd.DataFrame({'ds': [date_], 'holiday': [\"UAE-Holidays\"], 'lower_window': [-2], 'upper_window': [1]})], ignore_index=True)\n",
    "\n",
    "# Manually add December 30 and 31 holidays\n",
    "# We can add other desired hollidays manually if not in the holiday DataFrame\n",
    "manual_holidays = pd.DataFrame({\n",
    "    'ds': ['2023-12-30', '2023-12-31'],\n",
    "    'holiday': ['Manual-Holiday', 'Manual-Holiday'],\n",
    "    'lower_window': [-2, -2],\n",
    "    'upper_window': [1, 1]\n",
    "})\n",
    "\n",
    "# Convert 'ds' to datetime\n",
    "manual_holidays['ds'] = pd.to_datetime(manual_holidays['ds'])\n",
    "\n",
    "# Append manual holidays to the holiday DataFrame\n",
    "holiday = pd.concat([holiday, manual_holidays], ignore_index=True)\n",
    "\n",
    "# Convert 'ds' to datetime\n",
    "holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "# Display the updated holiday DataFrame\n",
    "print(holiday.head(10))\n",
    "print(holiday.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184e28f",
   "metadata": {},
   "source": [
    "### BACKTESTING WITH TUNED METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e0c67bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days = 1 # Forecast for the next day only\n",
    "forecast_start_date = max(total_orders_df.index) - timedelta(prediction_days) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85bc1eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-02-28 23:50:00')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Lists to store RMSE, MAE, and average orders per 20-minute interval for each merchant\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "average_orders_list = []\n",
    "\n",
    "forecasted_dfs = []\n",
    "\n",
    "# Create directory to save plots\n",
    "results_dir = 'results_10_mins'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "excel_path = os.path.join(results_dir, 'predicted_forecasts.xlsx')\n",
    "writer = pd.ExcelWriter(excel_path, engine='openpyxl')\n",
    "\n",
    "\n",
    "for feature in total_orders_df.columns:\n",
    "    \n",
    "    # Formatting\n",
    "    df_copy = total_orders_df[feature].copy().reset_index()\n",
    "    df_copy.columns = ['ds', 'y']\n",
    "    df_copy[['y']] = df_copy[['y']].apply(pd.to_numeric)\n",
    "    df_copy['ds'] = pd.to_datetime(df_copy['ds'])\n",
    "    \n",
    "    df_copy_ = df_copy[df_copy['ds'] < forecast_start_date]\n",
    "    \n",
    "    # Finding the right params_dict for this category\n",
    "    params_dict = dicts[feature]\n",
    "    \n",
    "    m = load_most_recent_checkpoint(\"prophet_checkpoints\")\n",
    "\n",
    "    #If there is no checkpoint (first time)\n",
    "    if m is None:\n",
    "        m = Prophet(\n",
    "        changepoint_prior_scale=params_dict['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=params_dict['seasonality_prior_scale'],\n",
    "        holidays_prior_scale=params_dict['holidays_prior_scale'],\n",
    "        seasonality_mode=params_dict['seasonality_mode'],\n",
    "        changepoint_range=params_dict['changepoint_range'],\n",
    "        holidays=holiday\n",
    "        )\n",
    "\n",
    "    m.fit(df_copy_)\n",
    "\n",
    "    future = m.make_future_dataframe(periods=prediction_days * 144, freq='10min')\n",
    "    fcst_prophet_train = m.predict(future)\n",
    "    \n",
    "    filter = fcst_prophet_train['ds'] >= forecast_start_date \n",
    "    predicted_df = fcst_prophet_train[filter][['ds', 'yhat']]\n",
    "    predicted_df = predicted_df.merge(df_copy, on='ds')\n",
    "\n",
    "    # Round up predictions\n",
    "    predicted_df['yhat'] = np.ceil(predicted_df['yhat'])\n",
    "\n",
    "    #print(predicted_df.head(20))\n",
    "    # Calculate RMSE and MAE\n",
    "    rmse = np.sqrt(np.mean((predicted_df['y'] - predicted_df['yhat'])**2))\n",
    "    mae = np.mean(np.abs(predicted_df['y'] - predicted_df['yhat']))\n",
    "\n",
    "    # Append RMSE and MAE to the lists\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "    # Calculate and store the average number of orders per 20-minute interval\n",
    "    average_orders = np.mean(predicted_df['y'])\n",
    "    average_orders_list.append(average_orders)\n",
    "\n",
    "    print(f\"{feature} - RMSE: {rmse:.2f}, MAE: {mae:.2f}, Average Orders per 10min: {average_orders:.2f}\")\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(predicted_df['ds'], predicted_df['y'], label='Actual')\n",
    "    plt.plot(predicted_df['ds'], predicted_df['yhat'], label='Predicted', linestyle='--')\n",
    "    plt.title(f'Actual vs Predicted for {feature}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Orders')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot to the results directory\n",
    "    plot_path = os.path.join(results_dir, f'{feature}_forecast.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    # Save the predicted DataFrame to the Excel file\n",
    "    predicted_df.to_excel(writer, sheet_name=feature, index=False)\n",
    "\n",
    "# Finalize and save the Excel file\n",
    "writer._save()\n",
    "writer.close()\n",
    "\n",
    "# Calculate average RMSE, MAE, and average orders across all merchants\n",
    "average_rmse = np.mean(rmse_list)\n",
    "average_mae = np.mean(mae_list)\n",
    "average_orders_across_merchants = np.mean(average_orders_list)\n",
    "\n",
    "print(f\"Average RMSE across all merchants: {average_rmse:.2f}\")\n",
    "print(f\"Average MAE across all merchants: {average_mae:.2f}\")\n",
    "print(f\"Average Orders per 10 min across all merchants: {average_orders_across_merchants:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54748bd6",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fedbc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Save the model with the current date in the filename\n",
    "model_filename = f'prophet_checkpoints/prophet_model_{current_date}.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(m, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
